{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6GzUxPz0r9-"
      },
      "source": [
        "# Trabajo Practico NLP - Detección de Tópicos y clasificación\n",
        "- ITBA 2024\n",
        "- Alumno: Gabriel Rey\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merged models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P7eCyxiT1rcu",
        "outputId": "1e5d8d12-903f-4a10-ddd3-6d7d9ae83cc7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "from dateutil.parser import parse\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from NLP_tools import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic import BERTopic\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.vectorizers import ClassTfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opensearch_data_model import Topic, TopicKeyword, News, os_client, TOPIC_INDEX_NAME, NEWS_INDEX_NAME\n",
        "from opensearch_io import *\n",
        "from opensearchpy import helpers\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inicializamos la base vectorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "init_opensearch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:/Users/gabri/OneDrive/Machine Learning/Github/ITBA-NLP/data/'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()\n",
        "PATH_REMOTO='/content/ITBA-NLP/data/'\n",
        "PATH=os.environ.get('PATH_LOCAL', PATH_REMOTO)\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<openai.OpenAI object at 0x0000023BBF766B90>\n"
          ]
        }
      ],
      "source": [
        "if PATH == os.environ.get('PATH_LOCAL'):\n",
        "    if os.environ.get('OPENAI_API_KEY'):\n",
        "        client = OpenAI(api_key= os.environ.get('OPENAI_API_KEY'))\n",
        "    else:\n",
        "        client = None\n",
        "    print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cargamos noticias \n",
        "- Notas:\n",
        "    - Se carga el segundo batch de noticias, luego de haber corrido al menos el primero y segundo batch con la notebook NLP_01_data\n",
        "    - Se debe haber generado el primer modelo en NLP_02_model\n",
        "    - Para cargar el segundo batch, se utiliza la fecha como identificador del lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar batch de noticias ( a partir del segundo batch en adelante ) por fecha previamente preprocesado en NLP_01_data \n",
        "choice = \"20240717\"  \n",
        "date_choice = choice[:4]+\"-\"+choice[4:6]+\"-\"+choice[6:8]\n",
        "batch_news = get_news(date_choice)\n",
        "\n",
        "if batch_news == []:\n",
        "    print(\"No hay noticias a procesar\")\n",
        "\n",
        "id_data     = [reg[0] for reg in batch_news]\n",
        "title_data  = [reg[1] for reg in batch_news]\n",
        "news_data   = [reg[2] for reg in batch_news]\n",
        "keywords    = [reg[3] for reg in batch_news]\n",
        "entities    = [reg[4] for reg in batch_news]\n",
        "created     = [reg[5] for reg in batch_news]\n",
        "\n",
        "# Cargar vocabulario previamente procesado\n",
        "with open(PATH+f'preproc_notebook/vocabulary_{choice}.json', 'r') as json_file:\n",
        "    vocab = json.load(json_file)\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesar batch de noticias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SPANISH_STOPWORDS = list(pd.read_csv(PATH+'spanish_stop_words.csv' )['stopwords'].values)\n",
        "SPANISH_STOPWORDS_SPECIAL = list(pd.read_csv(PATH+'spanish_stop_words_spec.csv' )['stopwords'].values)\n",
        "\n",
        "clean_data = Cleaning_text()\n",
        "\n",
        "proc_data = []\n",
        "for data_in in tqdm(news_data):\n",
        "    aux = clean_data.unicode(data_in)\n",
        "    aux = clean_data.urls(aux)\n",
        "    aux = clean_data.simbols(aux)\n",
        "    aux = clean_data.escape_sequence(aux)\n",
        "    aux = \" \".join([ word for word in aux.split() if word.lower() not in SPANISH_STOPWORDS_SPECIAL])\n",
        "    proc_data.append(aux)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo para el batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "        tokenizer=None,\n",
        "        max_df=0.9,\n",
        "        min_df=0.1,\n",
        "        ngram_range=(1, 2),\n",
        "        vocabulary=vocab,\n",
        "        # max_features=100_000\n",
        ")\n",
        "tfidf_vectorizer.fit(news_data)\n",
        "\n",
        "# Step 1 - Extract embeddings\n",
        "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "# Step 2 - Reduce dimensionality\n",
        "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
        "# Step 3 - Cluster reduced embeddings\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "# Step 4 - Tokenize topics\n",
        "vectorizer_model = tfidf_vectorizer\n",
        "# Step 5 - Create topic representation\n",
        "ctfidf_model = ClassTfidfTransformer()\n",
        "# Step 6 - (Optional) Fine-tune topic representations with a `bertopic.representation` model\n",
        "# representation_model = KeyBERTInspired()\n",
        "\n",
        "# All steps together\n",
        "topic_model_2 = BERTopic(\n",
        "  embedding_model=embedding_model,              # Step 1 - Extract embeddings\n",
        "  umap_model=umap_model,                        # Step 2 - Reduce dimensionality\n",
        "  hdbscan_model=hdbscan_model,                  # Step 3 - Cluster reduced embeddings\n",
        "  vectorizer_model=vectorizer_model,            # Step 4 - Tokenize topics\n",
        "  ctfidf_model=ctfidf_model,                    # Step 5 - Extract topic words\n",
        "  # representation_model=representation_model,  # Step 6 - (Optional) Fine-tune topic represenations\n",
        "  # language='multilingual',                    # This is not used if embedding_model is used.\n",
        "  verbose=True,\n",
        "  # calculate_probabilities=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "_, _ = topic_model_2.fit_transform(proc_data)\n",
        "\n",
        "# No necesito generar topicos, ni probabilidades, ni embeddings del modelo 2, ya que vamos a fusionar modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge de modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el modelo anterior\n",
        "topic_model_1 = BERTopic.load(PATH+\"modelos_notebook/bertopic_model_last\")\n",
        "print(f\"Topicos anteriores: {len(set(topic_model_1.get_topics().keys()))-1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combinar los modelos en uno solo\n",
        "merged_model = BERTopic.merge_models([topic_model_1, topic_model_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grabar modelo fusionado\n",
        "merged_model.save(PATH+f\"modelos_notebook/bertopic_model_last\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Cantidad de tópicos modelo 1: {len(topic_model_1.get_topic_info())} -- del 0 al {len(topic_model_1.get_topic_info())-1} (incluye topico -1)\")\n",
        "print(f\"Cantidad de tópicos modelo 2: {len(topic_model_2.get_topic_info())} -- del 0 al {len(topic_model_2.get_topic_info())-1} (incluye topico -1)\")\n",
        "print(f\"Cantidad de tópicos modelo merge: {len(merged_model.get_topic_info())} -- del 0 al {len(merged_model.get_topic_info())-1} (incluye topico -1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armar set de datos para inferir (ya procesados y nuevos)\n",
        "news_data_1 = get_news( process=True )\n",
        "df_news_1 = pd.DataFrame(news_data_1 , columns=[\"indice\", \"titulo\", \"noticia\", \"keywords\", \"entidades\", \"creado\", \"pos_id\"])\n",
        "df_news_1.sort_values(\"pos_id\", ascending=True, inplace=True)\n",
        "\n",
        "news_data_2 = {\"indice\":id_data, \"titulo\":title_data, \"noticia\":news_data, \"keywords\":keywords, \"entidades\":entities, \"creado\":created}\n",
        "df_news_2 = pd.DataFrame(news_data_2)\n",
        "\n",
        "df_unificado = pd.concat([df_news_1, df_news_2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listas de atributos de datos unificados\n",
        "u_id_data      = list(df_unificado['indice'])\n",
        "u_title_data   = list(df_unificado['titulo'])\n",
        "u_data         = list(df_unificado['noticia'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topicos validos (quitamos el topico -1)\n",
        "topics_to_save = list(merged_model.get_topics().keys())[1:]\n",
        "len(topics_to_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar cantidad de documentos que aportan a los topicos el modelo anterior, el modelo fusionado, y el total de ambos\n",
        "df_combined = merged_results(topic_model_1, merged_model)\n",
        "print(df_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topicos modelo merged\n",
        "merged_model.topic_labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elegir un topico que tenga aporte de noticias al topico por ambos modelos\n",
        "topic_id = 0\n",
        "docs_per_topics = [i for i, x in enumerate(merged_model.topics_) if x == topic_id]\n",
        "\n",
        "\n",
        "print(f\"Noticias totales del topico {topic_id}:\", len(docs_per_topics))\n",
        "# Lista de columnas que quieres excluir\n",
        "columnas_a_excluir = ['noticia', 'keywords','entidades','pos_id']\n",
        "\n",
        "\n",
        "df_query = df_unificado.loc[docs_per_topics, df_unificado.columns.difference(columnas_a_excluir)]\n",
        "df_query.style.set_properties(subset=['titulo'], **{'text-align': 'left'}).set_table_styles([{'selector': 'th', 'props': [('min-width', '50px')]}, {'selector': 'td', 'props': [('min-width', '140px')]}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtenemos transformaciones y embeddings del batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics_batch, probs_batch = merged_model.transform(news_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtenemos embeddings de todos los documentos\n",
        "docs_embedding_batch = merged_model.embedding_model.embed(news_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actualizar datos en news "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Marcar registros de noticias como procesados y grabar sus embeddings, topicos, probs \n",
        "update_news( id_data, docs_embedding_batch, topics_batch, probs_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actualizar en Topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener las fechas desde/hasta de los topicos existentes de opensearch\n",
        "from_date, to_date = get_topics_date()\n",
        "from_date, to_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "date_choice = choice[:4]+\"-\"+choice[4:6]+\"-\"+choice[6:8]\n",
        "\n",
        "# Preparar fechas para actualizar en los topicos ( excluyendo topico -1)\n",
        "from_date_to_save, to_date_to_save = update_topics_date(from_date, to_date, df_combined[1:], date_choice)\n",
        "from_date_to_save, to_date_to_save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topicos validos (quitamos el topico -1)\n",
        "topics_to_save = list(merged_model.get_topics().keys())[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener los nombres de los tópicos existentes\n",
        "topics_name = get_topics_opensearch()\n",
        "topics_name = [name['name'] for name in topics_name]\n",
        "topics_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar topicos existentes\n",
        "delete_index_opensearch(\"topic\")\n",
        "\n",
        "# Grabar todos los topicos en la base\n",
        "for topic_id in merged_model.get_topics().keys():\n",
        "    \n",
        "    if topic_id > -1:\n",
        "\n",
        "        topic_keywords_top  = top_keywords(topic_id, merged_model, PATH)\n",
        "        topic_entities_top  = get_top_entities_os(topic_id)\n",
        "        topic_documents_title, threshold  = get_top_documents_threshold(topic_id)\n",
        "        id_best_doc, title_best_doc, best_doc = best_document(topic_id, merged_model, docs_embedding_batch, u_id_data, u_title_data, u_data)\n",
        "        \n",
        "        topic_doc = Topic(\n",
        "            index = topic_id,\n",
        "            name = get_topic_name(''.join(topic_documents_title), topic_id, merged_model, client),\n",
        "            vector = list(merged_model.topic_embeddings_[topic_id + 1 ]),\n",
        "            similarity_threshold = threshold,\n",
        "            created_at = parse(from_date[topic_id]),\n",
        "            from_date = parse(from_date[topic_id]),\n",
        "            to_date = parse(to_date[topic_id]),\n",
        "            keywords = topic_keywords_top,\n",
        "            entities = topic_entities_top,\n",
        "            id_best_doc = id_best_doc,\n",
        "            title_best_doc = title_best_doc,\n",
        "            best_doc = best_doc,\n",
        "        )\n",
        "\n",
        "        topic_doc.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nota: Cada modelo puede representar ordenes distintos de los topicos, pero al fusionarlos, el orden del modelo 1 se mantiene en el fusionado y se agregan los nuevos al final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verificacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Temporalidad de los topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.dates import DateFormatter, AutoDateLocator\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "data_plot = {'topic': range(len(merged_model.get_topics().keys())-1),\n",
        "             'from': from_date_to_save,\n",
        "             'to': to_date_to_save}\n",
        "\n",
        "df_plot = pd.DataFrame(data_plot)\n",
        "df_plot['from'] = pd.to_datetime(df_plot['from'], format='ISO8601')\n",
        "df_plot['to'] = pd.to_datetime(df_plot['to'], format='ISO8601')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for index, row in df_plot.iterrows():\n",
        "    plt.plot([row['from'], row['to']], [row['topic'], row['topic']], marker='o')\n",
        "\n",
        "# Formatear las fechas en el eje X\n",
        "date_form = DateFormatter(\"%d-%m-%Y\")\n",
        "plt.gca().xaxis.set_major_formatter(date_form)\n",
        "\n",
        "# Ajustar los ticks del eje X para que no se repitan las fechas\n",
        "locator = AutoDateLocator()\n",
        "plt.gca().xaxis.set_major_locator(locator)\n",
        "\n",
        "plt.yticks(df_plot['topic'].unique())\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Número de Tópico')\n",
        "plt.title('Representación de Tópicos a lo Largo del Tiempo')\n",
        "plt.grid(True)\n",
        "\n",
        "# Rotar las etiquetas de fecha para mejor legibilidad (opcional)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Panel de Topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def panel_topicos(fecha):\n",
        "    df_topics = pd.DataFrame(get_topics_opensearch(fecha))\n",
        "\n",
        "    if not df_topics.empty:\n",
        "\n",
        "        columnas_a_excluir = ['vector', 'created_at', 'best_doc']\n",
        "\n",
        "        df_query = df_topics[df_topics.columns.difference(columnas_a_excluir)].sort_values(\"index\", ascending=True)\n",
        "        column_order = ['index','name','from_date', 'to_date', 'similarity_threshold', 'keywords', 'entities', 'id_best_doc', 'title_best_doc']\n",
        "\n",
        "        df_result = df_query.reindex(columns=column_order).style.set_properties(subset=['name'], **{'text-align': 'left'}).set_table_styles([{'selector': 'th','props': [('min-width', '40px')]},\n",
        "                                                                                                                                             {'selector': 'td', 'props': [('min-width', '140px')]}])\n",
        "        \n",
        "        return df_result\n",
        "    else:\n",
        "        print(\"No hay tópicos para los parámetros elegidos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# la fecha de consulta se relaciona con la vigencia, es decir con \"to_date\"\n",
        "fecha = None\n",
        "fecha = \"2024-07-18\"\n",
        "panel_topicos(fecha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Panel de noticias por topico ( filtrado por umbral del topico y fecha )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def panel_news(topic_id, fecha):\n",
        "\n",
        "    news_results = select_data_from_news(topic=topic_id)\n",
        "    if news_results:\n",
        "        if fecha in news_results[4]:\n",
        "            data_view = {   'ID': news_results[0],\n",
        "                            'titulo': news_results[1],\n",
        "                            'estimacion': news_results[3]}\n",
        "            \n",
        "            name, threshold = get_one_topic(topic_id)\n",
        "            print(f\"Noticias del topico {topic_id}: <<< {name} >>> | umbral: {threshold}\")\n",
        "            df_view = pd.DataFrame(data_view)\n",
        "            df_view.sort_values('estimacion', ascending=False, inplace=True)\n",
        "            df_result = df_view[df_view['estimacion'] > threshold]\n",
        "\n",
        "            return df_result\n",
        "        else:\n",
        "            print(\"No hay tópicos para los parámetros elegidos\")\n",
        "    else:\n",
        "        print(\"No hay tópicos para los parámetros elegidos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fecha = None\n",
        "fecha = '2024-07-16'\n",
        "topic_id = 8\n",
        "panel_news(topic_id, fecha)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el ultmo modelo fusionado\n",
        "merged_model = BERTopic.load(PATH+\"modelos_notebook/bertopic_model_last\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inferencia(texto_entrada):\n",
        "\n",
        "    results = merged_model.find_topics(texto_entrada)\n",
        "    if results[0][0] == -1:\n",
        "        return print(\"Sin resultados\")\n",
        "    else:\n",
        "        try:\n",
        "            index = results[0].index(-1)\n",
        "        except ValueError:\n",
        "            index = len(results[0])  # Si no hay -1, se mantiene toda la lista\n",
        "\n",
        "        # Eliminar los valores desde el índice encontrado hasta el final en ambas listas\n",
        "        results_ = (results[0][:index-1], results[1][:index-1])\n",
        "\n",
        "        print(\"El texto proporcionado se infiere en los siguientes tópicos: \")\n",
        "        names = [get_one_topic(topic_id) for topic_id in results_[0]]\n",
        "\n",
        "        t_keywords_entities = [get_topic_keywords_entities(topic_id) for topic_id in results_[0]]\n",
        "\n",
        "        lista_keywords = [list(tupla[0].keys()) for tupla in t_keywords_entities ]\n",
        "        lista_entities = [list(tupla[1].keys()) for tupla in t_keywords_entities ]\n",
        "\n",
        "        data = {\"topico\": results_[0],\n",
        "                \"nombre\": [name[0] for name in names],\n",
        "                \"estimacion\": results_[1],\n",
        "                \"keywords\": lista_keywords,\n",
        "                \"entities\": lista_entities}\n",
        "\n",
        "        df_res = pd.DataFrame(data)\n",
        "        df_res.sort_values(\"estimacion\", ascending=False, inplace=True)\n",
        "        return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El texto proporcionado se infiere en los siguientes tópicos: \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topico</th>\n",
              "      <th>nombre</th>\n",
              "      <th>estimacion</th>\n",
              "      <th>keywords</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>Crisis en la industria y empleo</td>\n",
              "      <td>0.566074</td>\n",
              "      <td>[soles, em, capacidad instalada, crecimiento]</td>\n",
              "      <td>[UIA, Unión Industrial Argentina, Argentina, Gobierno, Javier Milei, AMBA, Adimra, Demanda, Gobierno nacional, República Argentina]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Actualizaciones y cambios gubernamentales.</td>\n",
              "      <td>0.431123</td>\n",
              "      <td>[cuotas, categoría, multas]</td>\n",
              "      <td>[AFIP, DÓLAR, Gobierno, Argentina, Buenos Aires, Provincia, la Ley, ANSES, CBU, Ganancias]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Reuniones entre Gobierno y CGT</td>\n",
              "      <td>0.347498</td>\n",
              "      <td>[viviendas, pacto, ley, reunión]</td>\n",
              "      <td>[Gobierno, Javier Milei, Axel Kicillof, Consejo de Mayo, Congreso, Gobierno nacional, Provincia, CGT, PRO, Río Negro]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   topico                                      nombre  estimacion  \\\n",
              "0      11             Crisis en la industria y empleo    0.566074   \n",
              "1       3  Actualizaciones y cambios gubernamentales.    0.431123   \n",
              "2       1              Reuniones entre Gobierno y CGT    0.347498   \n",
              "\n",
              "                                        keywords  \\\n",
              "0  [soles, em, capacidad instalada, crecimiento]   \n",
              "1                    [cuotas, categoría, multas]   \n",
              "2               [viviendas, pacto, ley, reunión]   \n",
              "\n",
              "                                                                                                                              entities  \n",
              "0  [UIA, Unión Industrial Argentina, Argentina, Gobierno, Javier Milei, AMBA, Adimra, Demanda, Gobierno nacional, República Argentina]  \n",
              "1                                           [AFIP, DÓLAR, Gobierno, Argentina, Buenos Aires, Provincia, la Ley, ANSES, CBU, Ganancias]  \n",
              "2                [Gobierno, Javier Milei, Axel Kicillof, Consejo de Mayo, Congreso, Gobierno nacional, Provincia, CGT, PRO, Río Negro]  "
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto_entrada = 'Gobierno consiguió superávit financiero por sexto mes consecutivo'\n",
        "texto_entrada = 'capacidad instalada de la industria'\n",
        "\n",
        "inferencia(texto_entrada)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNGxTNO4yTgb9k2r4ffbTN0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
