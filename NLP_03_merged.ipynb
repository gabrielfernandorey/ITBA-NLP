{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielfernandorey/ITBA-NLP/blob/main/ITBA_nlp01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6GzUxPz0r9-"
      },
      "source": [
        "# Trabajo Practico NLP - Detección de Tópicos y clasificación\n",
        "- ITBA 2024\n",
        "- Alumno: Gabriel Rey\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merged models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P7eCyxiT1rcu",
        "outputId": "1e5d8d12-903f-4a10-ddd3-6d7d9ae83cc7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "from dateutil.parser import parse\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from NLP_tools import Cleaning_text, top_keywords, top_entities, get_topic_name, best_document, clean_all, topic_documents\n",
        "from core.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic import BERTopic\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.vectorizers import ClassTfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opensearch_data_model import Topic, TopicKeyword, News, os_client, TOPIC_INDEX_NAME, NEWS_INDEX_NAME\n",
        "from opensearchpy import helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inicializamos la base vectorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-18 10:23:28.082 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El índice Topic ya existe. Saltando inicialización de base de datos.\n",
            "El índice News ya existe. Saltando inicialización de base de datos.\n"
          ]
        }
      ],
      "source": [
        "init_opensearch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:/Users/gabri/OneDrive/Machine Learning/Github/ITBA-NLP/data/'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()\n",
        "PATH_REMOTO='/content/ITBA-NLP/data/'\n",
        "PATH=os.environ.get('PATH_LOCAL', PATH_REMOTO)\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PATH == os.environ.get('PATH_LOCAL'):\n",
        "    client = OpenAI(api_key= os.environ.get('OPENAI_API_KEY'))\n",
        "else:\n",
        "    from google.colab import userdata\n",
        "    client = OpenAI(api_key= userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cargamos noticias de dos chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the parquet file | ( lotes de prueba )\n",
        "\n",
        "df_params = {'0_1000':'0_1000_data.parquet',\n",
        "             '1000_2000':'1000_2000_data.parquet',\n",
        "             '2000_3000':'2000_3000_data.parquet',\n",
        "             'df_joined':'df_joined_2024-04-01 00_00_00.parquet'\n",
        "            }\n",
        "\n",
        "chunk = '0_1000'\n",
        "df_parquet_1 = pd.read_parquet(PATH+df_params[chunk])\n",
        "data_1 = list(df_parquet_1['in__text'])\n",
        "\n",
        "chunk = '1000_2000'\n",
        "df_parquet_2 = pd.read_parquet(PATH+df_params[chunk])\n",
        "data_2 = list(df_parquet_2['in__text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unificamos datos\n",
        "df_parquet = pd.concat([df_parquet_1, df_parquet_2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHLnakcu2MOq"
      },
      "source": [
        "### Modelo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar modelo 1 \n",
        "chunk = '0_1000'\n",
        "\n",
        "topic_model_1 = BERTopic.load(PATH+f\"modelos/bertopic_model_{chunk}\")\n",
        "topics_1 = np.load(PATH+f\"modelos/topics_{chunk}.npy\")\n",
        "probs_1 = np.load(PATH+f\"modelos/probs_{chunk}.npy\")\n",
        "\n",
        "# Cargar los embeddings \n",
        "docs_embedding_1 = np.load(PATH+f\"modelos/topic_embeddings_{chunk}.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar modelo 2\n",
        "chunk = '1000_2000'\n",
        "\n",
        "topic_model_2 = BERTopic.load(PATH+f\"modelos/bertopic_model_{chunk}\")\n",
        "topics_2 = np.load(PATH+f\"modelos/topics_{chunk}.npy\")\n",
        "probs_2 = np.load(PATH+f\"modelos/probs_{chunk}.npy\")\n",
        "\n",
        "# Cargar los embeddings \n",
        "docs_embedding_2 = np.load(PATH+f\"modelos/topic_embeddings_{chunk}.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all models into one\n",
        "merged_model = BERTopic.merge_models([topic_model_1, topic_model_2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de tópicos modelo 1: 17 (incluye topico -1)\n",
            "Cantidad de tópicos modelo 2: 18 (incluye topico -1)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Cantidad de tópicos modelo 1: {len(topic_model_1.get_topic_info())} (incluye topico -1)\")\n",
        "print(f\"Cantidad de tópicos modelo 2: {len(topic_model_2.get_topic_info())} (incluye topico -1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de tópicos modelo merge: 19 (incluye topico -1)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Cantidad de tópicos modelo merge: {len(merged_model.get_topic_info())} (incluye topico -1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparamos modelos ordenados por topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count1</th>\n",
              "      <th>Count2</th>\n",
              "      <th>Merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>140.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>130.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>116.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>112.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>84.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>52.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>19.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Topic  Count1  Count2  Merged\n",
              "0      -1   140.0   119.0     259\n",
              "1       0   157.0   320.0     326\n",
              "2       1   130.0   169.0     130\n",
              "3       2   116.0    57.0     436\n",
              "4       3   112.0    49.0     183\n",
              "5       4    84.0    36.0     176\n",
              "6       5    52.0    34.0      52\n",
              "7       6    30.0    31.0      30\n",
              "8       7    27.0    29.0      56\n",
              "9       8    26.0    26.0      83\n",
              "10      9    26.0    22.0      62\n",
              "11     10    22.0    22.0      37\n",
              "12     11    20.0    15.0      42\n",
              "13     12    19.0    15.0      19\n",
              "14     13    18.0    15.0      44\n",
              "15     14    11.0    15.0      25\n",
              "16     15    10.0    14.0      10\n",
              "17     16     NaN    12.0      15\n",
              "18     17     NaN     NaN      15"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtener documentos de cada tópico y modelo\n",
        "topic_freq_1 = topic_model_1.get_topic_freq()\n",
        "topic_freq_2 = topic_model_2.get_topic_freq()\n",
        "topic_freq_m = merged_model.get_topic_freq()\n",
        "\n",
        "# Ordenar los DataFrames por 'Topic'\n",
        "df1 = topic_freq_1.sort_values(by='Topic').reset_index(drop=True)\n",
        "df2 = topic_freq_2.sort_values(by='Topic').reset_index(drop=True)\n",
        "df3 = topic_freq_m.sort_values(by='Topic').reset_index(drop=True)\n",
        "\n",
        "# Renombrar las columnas 'Count' para diferenciar ambos DataFrames\n",
        "df1 = df1.rename(columns={'Count': 'Count1'})\n",
        "df2 = df2.rename(columns={'Count': 'Count2'})\n",
        "df3 = df3.rename(columns={'Count': 'Merged'})\n",
        "\n",
        "# Combinar los DataFrames por 'Topic'\n",
        "df_combined = pd.merge(df1, df2, on='Topic', how='outer')\n",
        "df_combined = pd.merge(df_combined, df3, on='Topic', how='outer')\n",
        "\n",
        "df_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recuperar todos los topicos y sus etiquetas generadas por el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136 Marzo fue el décimo mes consecutivo en romper récords de altas temperaturas globales\n",
            "162 Último día del fin de semana largo: cuál es el pronóstico del tiempo para este martes\n",
            "223 Emiten alerta naranja por viento y lluvia para este martes\n",
            "254 Pronóstico: para mañana se espera un aumento de la temperatura y alerta por Zonda y sectores del Gan Mendoza\n",
            "354 El tiempo en Santiago del Estero: máxima de 26ºC y probabilidad de precipitaciones para el inicio de abril\n",
            "359 Inicio de semana fresco y con un cielo parcialmente nublado - MDZ Online\n",
            "505 El cielo estará nublado y se esperan lluvias durante toda la jornada en Tucumán\n",
            "517 Lunes caluroso en Misiones, con pronostico de lluvias y chaparrones aislados\n",
            "907 Clima en Córdoba: fuerte descenso de la temperatura para el lunes, ¿llega la lluvia?\n",
            "966 Alerta por viento y lluvia, este martes y miércoles, en Neuquén y Río Negro: habrá ráfagas de 120 km/h\n",
            "991 🟠 Lanzaron una alerta naranja por fuertes vientos: qué provincias serán afectadas\n",
            "1085 Pronostican que el fenómeno Niña volverá para la primavera o el verano\n",
            "1146 Alerta por vientos de hasta 120km/h este martes y miércoles, en Neuquén y Río Negro: qué precauciones tomar\n",
            "1191 Fuerte temporal en Aguas Blancas: \"las calles eran ríos\", expresaron los vecinos\n",
            "1235 Pronóstico del tiempo en Mendoza: abril arrancó bien otoñal y se mantendrá toda la semana\n",
            "1255 Paraná: suspenden actividades por las inclemencias del tiempo\n",
            "1346 Alerta por tormentas fuertes y granizo en cuatro provincias\n",
            "1353 Mercurio retrógrado en Aries del 2 de abril 2024: qué significa y a qué signos afecta\n",
            "1419 Clima fresco con probabilidad de chaparrones y viento sur en Villa Carlos\n",
            "1565 SMN: la semana inicia y continúa con lluvias y tormentas\n",
            "1691 El tiempo en Rosario: lunes con más precipitaciones, pero sólo hasta la mañana\n",
            "1708 Otra vez malas noticias para Mar del Plata: se esperan lluvias para este lunes feriado\n",
            "1752 Clima en Córdoba: descenso de temperatura y probabilidad de lluvias para este lunes 1 de abril\n",
            "1927 Alerta hoy por tormentas y granizo: cuatro provincias afectadas\n",
            "1934 Clima en Buenos Aires: cómo terminará el fin de semana XXL y el pronóstico para los próximos días\n"
          ]
        }
      ],
      "source": [
        "# docs de 0-1000 primer chunk\n",
        "# docs de 1000-2000 segundo chunk\n",
        "docs = [i for i, x in enumerate(merged_model.topics_) if x == 14]\n",
        "for i in docs:\n",
        "    print(i, df_parquet.iloc[i]['in__title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Buscar topicos ingresando un texto en el modelo merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([14, 2, 7, 5, 13], [0.5230975, 0.33653283, 0.2686169, 0.25594658, 0.2443951])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_res = merged_model.find_topics(\"cambio climatico\")\n",
        "topic_res"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNGxTNO4yTgb9k2r4ffbTN0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
