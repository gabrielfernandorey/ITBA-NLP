# ITBA-NLP

### Trabajo Pr치ctico NLP Detecci칩n de T칩picos y clasificaci칩n

### Instrucciones
  1. Abrir terminal y clonar el repositorio: ```git clone https://github.com/gabrielfernandorey/ITBA-NLP.git```
  2. Crear un ambiente virtual: ```virtualenv itba-nlp-env```
  3. Activar ambiente virtual: ```.\itba-nlp-env\Scripts\activate```
  4. Cambiar a carpeta ITBA-NLP e instalar dependencias: ```pip install -r requirements.txt```
  5. Instalar Docker
  6. Instalacion de OpenSearch:
     -  ```docker pull opensearchproject/opensearch:latest```
     -  ```docker run -it -p 9200:9200 -p 9600:9600 -e OPENSEARCH_INITIAL_ADMIN_PASSWORD=PassWord#1234! -e "discovery.type=single-node"  --name opensearch-node opensearchproject/opensearch:latest```
  7. Crear y configurar archivo .env: El archivo debe estar en la carpeta ITBA-NLP y contener las siguientes lineas
     ```
     PATH_LOCAL='...path.../ITBA-NLP/data/'
     # Si se dispone de API_KEY
     OPENAI_API_KEY= 
     MODEL='gpt-4o-mini'
     BATCH_NEWS=1000
     ```
  8. Procesos:
     - Ejecutar la notebook NLP_01_data para generar los indices news y topic de la base, obtener keywords y entidades, y grabar noticias en news.
     - Ejecutar NLP_02_model para modelar los topicos con el lote de noticias utilizado en NLP_01_data
     - Ejecutar la notebook NLP_01_data nuevamente para grabar noticias en news de un nuevo lote (nueva fecha) de noticias.
     - Ejecutar la notebook NLP_03_merged para fusionar los primeros dos modelos.
     - El procedimiento continua procesando un nuevo lote de una nueva fecha en NLP_01_data para luego fusionar en NLP_03_merged
     

