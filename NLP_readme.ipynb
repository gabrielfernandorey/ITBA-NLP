{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Practico NLP - Detección de Tópicos y clasificación\n",
    "- ITBA 2024\n",
    "- Alumno: Gabriel Rey\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guia del trabajo practico ( notebooks )\n",
    "\n",
    "El trabajo practico comprende los siguientes archivos de trabajo:\n",
    "- NLP_01_data\n",
    "- NLP_02_model\n",
    "- NLP_03_merged\n",
    "- NLP_tools\n",
    "- .env\n",
    "- opensearch_data_model.py\n",
    "- opensearch_io.py\n",
    "- spanish_stop_words.csv\n",
    "- spanish_stop_words_spec.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP_01_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta notebook se utiliza para:\n",
    "- obtener un lote predefinido de las noticias de una fecha dada\n",
    "    - Se descarga de Huggingface un archivo de una fecha determinada. Como se ha detectado que en la descarga de cualquier fecha existen datos de otras fechas y se procede a:\n",
    "        - Eliminarlos\n",
    "        - Obtener un set de datos para esa fecha acotado mediante sampling para realizar las pruebas. (definido en .env)\n",
    "        - el archivo resultante es {fecha}.parquet y se guarda en 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se realiza el ejercicio de obtención de entities y keywords, mas allá de tenerlas provistas en el set de datos de origen.\n",
    "    - los archivos que se generan son:\n",
    "        - entities_{fecha}.json\n",
    "        - keywords_{fecha}.json\n",
    "        - se guardan en 'data/preproc_notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- se obtiene el vocabulario para utilizar en BERTopic\n",
    "    - el archivo que se genera es:\n",
    "        - vocabulary_{fecha}.json\n",
    "        - se guarda en 'data/preproc_notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se guardan las noticias en el indice 'news' de la base opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP_02_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta notebook realiza las siguientes tareas:\n",
    "\n",
    "- inicializa los indices de la base opensearch\n",
    "- carga el archivo de noticias acotado \n",
    "- las keywords y entities de los documentos se cargan del indice news de opensearch\n",
    "- realiza un preprocesamiento mínimo del texto, pero no se le quita el sentido semántico para que mediante SentenceTransformer se puedan capturar embeddings de mejor calidad.\n",
    "- configuración del modelo BERTopic\n",
    "    - el modelo que se genera se guarda en 'data/modelos_notebook'\n",
    "    - el archivo resultante es bertopic_model_{fecha}\n",
    "- se generan los embeddings del modelo\n",
    "    - se guarda en 'data/modelos_notebook'\n",
    "    - el archivo resultante es docs_embeddings_{fecha}\n",
    "- se muestra resultados luego del entrenamiento\n",
    "- se graba en el indice Topic y se actualiza en News\n",
    "    - si no existe OPENAI_API_KEY definida en .env se graba como nombre del topico los labels del topico que otorrga el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
