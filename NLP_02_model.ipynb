{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielfernandorey/ITBA-NLP/blob/main/ITBA_nlp01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6GzUxPz0r9-"
      },
      "source": [
        "# Trabajo Practico NLP - Detección de Tópicos y clasificación\n",
        "- ITBA 2024\n",
        "- Alumno: Gabriel Rey\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P7eCyxiT1rcu",
        "outputId": "1e5d8d12-903f-4a10-ddd3-6d7d9ae83cc7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "from dateutil.parser import parse\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from NLP_tools import Cleaning_text, top_keywords, top_entities, get_topic_name, best_document, clean_all, topic_documents\n",
        "from core.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic import BERTopic\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.vectorizers import ClassTfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opensearch_data_model import Topic, TopicKeyword, News, os_client, TOPIC_INDEX_NAME, NEWS_INDEX_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inicializamos la base vectorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-02 21:48:37.061 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El índice Topic ya existe. Saltando inicialización de base de datos.\n",
            "El índice News ya existe. Saltando inicialización de base de datos.\n"
          ]
        }
      ],
      "source": [
        "init_opensearch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:/Users/gabri/OneDrive/Machine Learning/Github/ITBA-TP/data/'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()\n",
        "PATH_REMOTO='/content/ITBA-TP/data/'\n",
        "PATH=os.environ.get('PATH_LOCAL', PATH_REMOTO)\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PATH == os.environ.get('PATH_LOCAL'):\n",
        "    client = OpenAI(api_key= os.environ.get('OPENAI_API_KEY'))\n",
        "else:\n",
        "    from google.colab import userdata\n",
        "    client = OpenAI(api_key= userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHLnakcu2MOq"
      },
      "source": [
        "### Data de noticias original "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cmp3cLLv28-T",
        "outputId": "2d83d8fc-9241-448a-98a1-6230eb29ce2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_params = {'0_1000':'0_1000_data.parquet',\n",
        "             '1000_2000':'1000_2000_data.parquet',\n",
        "             '2000_3000':'2000_3000_data.parquet',\n",
        "             'df_joined':'df_joined_2024-04-01 00_00_00.parquet'\n",
        "            }\n",
        "\n",
        "chunk = os.environ.get('CHUNK')\n",
        "\n",
        "df_parquet = pd.read_parquet(PATH+df_params[chunk])\n",
        "data = list(df_parquet['in__text'])\n",
        "\n",
        "# Cantidad total de documentos\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar vocabulario\n",
        "with open(PATH+f'modelos/entities_vocabulary{chunk}.json', 'r') as json_file:\n",
        "    vocab_entities = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### StopWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stopwords\n",
        "SPANISH_STOPWORDS = list(pd.read_csv(PATH+'spanish_stop_words.csv' )['stopwords'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "        tokenizer=None,\n",
        "        max_df=0.9,\n",
        "        min_df=0.1,\n",
        "        ngram_range=(1, 2),\n",
        "        vocabulary=vocab_entities,\n",
        "        # max_features=100_000\n",
        ")\n",
        "tfidf_vectorizer.fit(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Capas del modelo BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mpb75EAM3R53"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Extract embeddings\n",
        "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "# Step 2 - Reduce dimensionality\n",
        "umap_model = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric='cosine', random_state=42)\n",
        "# Step 3 - Cluster reduced embeddings\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "# Step 4 - Tokenize topics\n",
        "vectorizer_model = tfidf_vectorizer\n",
        "# Step 5 - Create topic representation\n",
        "ctfidf_model = ClassTfidfTransformer()\n",
        "# Step 6 - (Optional) Fine-tune topic representations with a `bertopic.representation` model\n",
        "representation_model = KeyBERTInspired()\n",
        "\n",
        "# All steps together\n",
        "topic_model = BERTopic(\n",
        "  embedding_model=embedding_model,            # Step 1 - Extract embeddings\n",
        "  umap_model=umap_model,                      # Step 2 - Reduce dimensionality\n",
        "  hdbscan_model=hdbscan_model,                # Step 3 - Cluster reduced embeddings\n",
        "  vectorizer_model=vectorizer_model,          # Step 4 - Tokenize topics\n",
        "  ctfidf_model=ctfidf_model,                  # Step 5 - Extract topic words\n",
        "  representation_model=representation_model,  # Step 6 - (Optional) Fine-tune topic represenations\n",
        "  language='spanish',\n",
        "  verbose=True,\n",
        "  # calculate_probabilities=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_callback(stage, **kwargs):\n",
        "    print(f\"Stage: {stage}\")\n",
        "    for key, value in kwargs.items():\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_callback(stage=\"start_training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar modelo entrenado o saltar celda y entrenar\n",
        "ahora = datetime.today()\n",
        "topic_model = BERTopic.load(PATH+\"modelos/bertopic_model_app\")\n",
        "topics = np.load(PATH+\"modelos/topics_app.npy\")\n",
        "probs = np.load(PATH+\"modelos/probs_app.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics, probs = topic_model.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grabar modelo\n",
        "topic_model.save(PATH+\"modelos/bertopic_model_nb\")\n",
        "np.save(PATH+\"modelos/topics_nb.npy\", topics)\n",
        "np.save(PATH+\"modelos/probs_nb.npy\", probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de tópicos 19 (incluye topico -1)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Cantidad de tópicos {len(set(topics))} (incluye topico -1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejemplo para tópico: 12\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>407</td>\n",
              "      <td>Advierten que el desguace del Senasa amenaza c...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>Sigue la discordia entre los gobernadores y la...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80</td>\n",
              "      <td>El Congreso constituye mañana la comisión de i...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>108</td>\n",
              "      <td>El Senado activa siete comisiones para salir d...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>124</td>\n",
              "      <td>Un proyecto de ley en Florida busca limitar la...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>130</td>\n",
              "      <td>Los piqueteros preparan nuevas medidas de fuer...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>665</td>\n",
              "      <td>Ley Ómnibus II: el Gobierno llevará el texto f...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>571</td>\n",
              "      <td>Diputados de UCR solicitaron al Gobierno un in...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>410</td>\n",
              "      <td>Despidos: el radicalismo pidió informes por el...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>376</td>\n",
              "      <td>Cobos reclama un informe a Nación por la paral...</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34</td>\n",
              "      <td>Se profundiza la crisis inmobiliaria de China:...</td>\n",
              "      <td>0.9962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>256</td>\n",
              "      <td>Despidos en Parques Nacionales: \"Vienen por lo...</td>\n",
              "      <td>0.8701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>La CTA Autónoma alertó que habrá nuevas medida...</td>\n",
              "      <td>0.7985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>207</td>\n",
              "      <td>Un referente de Miguel Ángel Pichetto reveló c...</td>\n",
              "      <td>0.7903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>961</td>\n",
              "      <td>Paritaria siderúrgica: la UOM marcha este juev...</td>\n",
              "      <td>0.7859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>804</td>\n",
              "      <td>Críticas y quejas por la paralización de la ob...</td>\n",
              "      <td>0.7652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>684</td>\n",
              "      <td>Verón es el nuevo presidente de Estudiantes</td>\n",
              "      <td>0.7333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>255</td>\n",
              "      <td>Unión convoca a asambleas de socios para el ju...</td>\n",
              "      <td>0.7293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>740</td>\n",
              "      <td>Un gobernador puso en duda su apoyo a la Ley B...</td>\n",
              "      <td>0.7196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0                                                  1       2\n",
              "11  407  Advierten que el desguace del Senasa amenaza c...  1.0000\n",
              "2    65  Sigue la discordia entre los gobernadores y la...  1.0000\n",
              "3    80  El Congreso constituye mañana la comisión de i...  1.0000\n",
              "4   108  El Senado activa siete comisiones para salir d...  1.0000\n",
              "5   124  Un proyecto de ley en Florida busca limitar la...  1.0000\n",
              "6   130  Los piqueteros preparan nuevas medidas de fuer...  1.0000\n",
              "14  665  Ley Ómnibus II: el Gobierno llevará el texto f...  1.0000\n",
              "13  571  Diputados de UCR solicitaron al Gobierno un in...  1.0000\n",
              "12  410  Despidos: el radicalismo pidió informes por el...  1.0000\n",
              "10  376  Cobos reclama un informe a Nación por la paral...  1.0000\n",
              "0    34  Se profundiza la crisis inmobiliaria de China:...  0.9962\n",
              "9   256  Despidos en Parques Nacionales: \"Vienen por lo...  0.8701\n",
              "1    56  La CTA Autónoma alertó que habrá nuevas medida...  0.7985\n",
              "7   207  Un referente de Miguel Ángel Pichetto reveló c...  0.7903\n",
              "18  961  Paritaria siderúrgica: la UOM marcha este juev...  0.7859\n",
              "17  804  Críticas y quejas por la paralización de la ob...  0.7652\n",
              "15  684        Verón es el nuevo presidente de Estudiantes  0.7333\n",
              "8   255  Unión convoca a asambleas de socios para el ju...  0.7293\n",
              "16  740  Un gobernador puso en duda su apoyo a la Ley B...  0.7196"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Busqueda de documentos por topico, ordenados por mayor probabilidad\n",
        "\n",
        "T = topic_model.get_document_info(data)\n",
        "docs_per_topics = T.groupby([\"Topic\"]).apply(lambda x: x.index).to_dict()\n",
        "\n",
        "topic =12\n",
        "#topic = np.random.randint(0, len(docs_per_topics)-1)\n",
        "\n",
        "print(\"Ejemplo para tópico:\", topic)\n",
        "\n",
        "doc_probs_x_topic = []\n",
        "for doc in docs_per_topics[topic]:\n",
        "    doc_probs_x_topic.append([doc, df_parquet.iloc[doc].in__title, round(probs[doc],4)])\n",
        "\n",
        "df_query_1 = pd.DataFrame(doc_probs_x_topic)\n",
        "df_query_1.sort_values(2, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_query_1.iloc[11][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Criterio de corte (umbral)\n",
        "El criterio de corte utilizado para filtrar las noticias que pertenecen a un topico es el valor de -1 desvio std."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular la media, el desvío estándar\n",
        "mean = np.mean(doc_probs_x_topic)\n",
        "std_dev = np.std(doc_probs_x_topic)\n",
        "\n",
        "# Crear el histograma \n",
        "plt.hist(doc_probs_x_topic, bins=10, edgecolor='black')\n",
        "\n",
        "# Añadir líneas para la media, la moda y el desvío estándar\n",
        "plt.axvline(mean, color='r', linestyle='dashed', linewidth=1, label=f'Media: {mean:.2f}')\n",
        "plt.axvline(mean - std_dev, color='b', linestyle='dashed', linewidth=1, label=f'-1 STD: {mean - std_dev:.2f}')\n",
        "\n",
        "\n",
        "# Añadir títulos y etiquetas\n",
        "plt.title(f'Histograma de probabilidades topico: {topic}')\n",
        "plt.xlabel('Valor')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documentos mas representativos de un topico "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [1]  Obtenido por el metodo del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs_representative = topic_model.get_representative_docs(topic=topic)\n",
        "docs_representative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [2] Obtenido por busqueda de probabilidad de documentos perteneciente al topico ( utilizando el umbral de corte )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la función de estilo\n",
        "def color_rows(row, label, value):\n",
        "    if row[label] >= value:\n",
        "        return ['color: cyan'] * len(row)\n",
        "    else:\n",
        "        return [''] * len(row)\n",
        "    \n",
        "# Agrupamos documentos por topico\n",
        "T = topic_model.get_document_info(data)\n",
        "docs_per_topics = T.groupby([\"Topic\"]).apply(lambda x: x.index).to_dict()\n",
        "\n",
        "# Obtener los IDs de los documentos y sus probabilidades \n",
        "docs_ids = []\n",
        "docs_topic = []\n",
        "doc_probs_x_topic = []\n",
        "for doc_ID in tqdm(docs_per_topics[topic]):\n",
        "    docs_ids.append(df_parquet.index[doc_ID])\n",
        "    doc_probs_x_topic.append(probs[doc_ID])\n",
        "\n",
        "# Calcular la media, el desvío estándar\n",
        "mean = np.mean(doc_probs_x_topic)\n",
        "std_dev = np.std(doc_probs_x_topic)\n",
        "threshold = mean - std_dev\n",
        "\n",
        "# Crear una consulta de múltiples IDs\n",
        "index_name = 'news'\n",
        "mget_query = {\n",
        "    \"docs\": [{\"_index\": index_name, \"_id\": doc_id} for doc_id in docs_ids]\n",
        "}\n",
        "# Realizar la búsqueda de múltiples IDs\n",
        "response = os_client.mget(body=mget_query, index=index_name)\n",
        "\n",
        "# Procesar la respuesta\n",
        "for i, doc in enumerate(response['docs']):\n",
        "    if doc['found']:\n",
        "        idx = doc['_id']\n",
        "        title = df_parquet.iloc[docs_per_topics[topic][i]].in__title\n",
        "        prob_doc = probs[docs_per_topics[topic][i]]\n",
        "        \n",
        "        if 'entities' in doc['_source']:\n",
        "            ent = doc['_source']['entities']\n",
        "        else:\n",
        "            ent = []\n",
        "\n",
        "        docs_topic.append([idx, title, prob_doc, ent])\n",
        "\n",
        "\n",
        "df_view = pd.DataFrame(docs_topic, columns = ['indice','titulo','prob','entidades']).sort_values('prob', ascending=False)\n",
        "df_view.style.apply(lambda row: color_rows(row, 'prob', threshold), axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nota: Los documentos mas representativos encontrados utilizando el metodo \"get_representative_docs\" no refleja lo mismo que encontrando los documentos por probabilidades maximas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [3] Por similitud coseno del topico a los tres documento mas cercanos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar los embeddings en un archivo de NumPy o procesar la celda inferior\n",
        "docs_embedding = np.load(PATH+f\"modelos/topic_embeddings_{chunk}.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtenemos embeddings de todos los documentos\n",
        "docs_embedding = topic_model.embedding_model.embed(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar los embeddings en un archivo de NumPy\n",
        "np.save(PATH+f\"modelos/topic_embeddings_{chunk}.npy\", docs_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtenemos la matriz de similitud coseno entre topicos y documentos\n",
        "sim_matrix = cosine_similarity(topic_model.topic_embeddings_, docs_embedding)\n",
        "sim_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Similitud coseno entre el topico y los documentos del topico elegido\n",
        "s_coseno = []\n",
        "for i in docs_per_topics[topic]:\n",
        "    s_coseno.append(cosine_similarity([topic_model.topic_embeddings_[topic + 1]], [docs_embedding[i]])[0][0])\n",
        "\n",
        "# Indices\n",
        "idx_coseno_sort = np.argsort(s_coseno)[::-1]\n",
        "\n",
        "for idx in idx_coseno_sort[:3]:\n",
        "    print(idx, df_parquet.iloc[docs_per_topics[topic][idx]].in__title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nota: Del mismo modo que en el punto anterior, los documentos mas cercanos al topico no coinciden no son exactamente los mismos que los hallados en el punto 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [4] Primer documento mas cercano al embedding del topico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Documento de maxima similitud con el topico\n",
        "\n",
        "simil_docs_topic = sim_matrix[topic + 1].argmax()\n",
        "print(f\"Noticia de maxima similitud con el topico: {topic}\")\n",
        "print(f\"Doc ID: {df_parquet.index[simil_docs_topic]}\")\n",
        "print(f\"Titulo: {df_parquet.iloc[simil_docs_topic].in__title}\")\n",
        "print(f\"Noticia: {data[simil_docs_topic][:80]}...\")\n",
        "best_doc = data[simil_docs_topic]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"\"Ojo, con la selección del mas cercano respecto a las probabilidades de los docs del topico\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Keywords de solo un topico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keywords = topic_model.topic_representations_[topic]\n",
        "topic_keywords = [TopicKeyword(name=keyword, score=score) for keyword, score in keywords if keyword != '']\n",
        "topic_keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Nota: el umbral de corte para las keywords es la media, se tomaran hasta 10 keywords mientras no supere el umbral de corte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freq_k = []\n",
        "for name_score in topic_keywords:\n",
        "    freq_k.append(name_score['score'])\n",
        "umbral_k = np.array(freq_k).mean()\n",
        "umbral_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_keywords_top = {}\n",
        "for name_score in topic_keywords:\n",
        "    if name_score['score'] >= umbral_k:\n",
        "        topic_keywords_top[name_score['name']] = name_score['score']\n",
        "\n",
        "topic_keywords_top\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Entidades de un Topico a partir de los n documentos mas cercanos al embedding del topico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entidades de documentos ordenados por similitud del topico elelgido\n",
        "n_docs = 5 # n docs cercanos\n",
        "entities_topic = []\n",
        "for doc in df_view[:n_docs].iterrows():\n",
        "    entities_topic.append(doc[1][3])\n",
        "\n",
        "from collections import defaultdict \n",
        "\n",
        "# Crear un diccionario para contar en cuántos documentos aparece cada palabra\n",
        "document_frequencies = defaultdict(int)\n",
        "\n",
        "# Crear un conjunto para cada documento y contar las palabras únicas\n",
        "for lista in entities_topic:\n",
        "    unique_words = set(lista)\n",
        "    for palabra in unique_words:\n",
        "        document_frequencies[palabra] += 1\n",
        "\n",
        "# Ordenar las palabras por la frecuencia de documentos de mayor a menor\n",
        "sorted_frequencies = sorted(document_frequencies.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "freq_e = []\n",
        "for item in sorted_frequencies:\n",
        "    freq_e.append(item[1])\n",
        "umbral_e = np.array(freq_e).mean()\n",
        "\n",
        "# Imprimir el resultado ordenado de las primeras 10 entidades segun criterio de corte\n",
        "topic_entities_top = {}\n",
        "c=0\n",
        "for idx in range(len(sorted_frequencies)):\n",
        "    if sorted_frequencies[idx][1] >= umbral_e:\n",
        "        if c != 10:\n",
        "            topic_entities_top[sorted_frequencies[idx][0]] = sorted_frequencies[idx][1]\n",
        "        else:\n",
        "            break\n",
        "        c += 1\n",
        "\n",
        "topic_entities_top\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grabar todos los registros en Topic y actualizar en News"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar o saltar carga y procesar celda inferior\n",
        "with open(PATH+f'modelos/entities{chunk}.json', 'r') as json_file:\n",
        "    entities = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grabar todos los topicos en la base\n",
        "for topic in topic_model.get_topics().keys():\n",
        "    if topic > -1:\n",
        "\n",
        "        topic_keywords_top  = top_keywords(topic, topic_model)\n",
        "        topic_entities_top  = top_entities(topic, topic_model, docs_embedding, data, entities)\n",
        "        topic_documents_ids, threshold  = topic_documents(topic, topic_model, probs, df_parquet, data)\n",
        "\n",
        "        topic_doc = Topic(\n",
        "            index = topic,   \n",
        "            name = get_topic_name(''.join({**topic_keywords_top, **topic_entities_top}), client),\n",
        "            vector = list(topic_model.topic_embeddings_[topic + 1 ]), \n",
        "            similarity_threshold = threshold,                      \n",
        "            created_at = datetime.now(),\n",
        "            to_date = parse('2024-04-02'),\n",
        "            from_date = parse('2024-04-01'),         \n",
        "            keywords = topic_keywords_top,\n",
        "            entities = topic_entities_top,\n",
        "            best_doc = best_document(topic, topic_model, docs_embedding, data),\n",
        "            docs = topic_documents_ids\n",
        "        ) \n",
        "\n",
        "        topic_doc.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Actualizar datos en News"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Marcar registros de noticias procesados\n",
        "index_name = 'news'\n",
        "search_query = {\n",
        "    'query': {\n",
        "        'match': {\n",
        "            'process': False  \n",
        "        }\n",
        "    },\n",
        "    'size': 10000\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda\n",
        "response = os_client.search( body=search_query, index=index_name )\n",
        "\n",
        "for i, reg in enumerate(response['hits']['hits']):\n",
        "    doc_id = reg['_id']\n",
        "    \n",
        "    update_body = {\n",
        "                    \"doc\": {\n",
        "                        \n",
        "                        \"process\": True\n",
        "                    }\n",
        "    }\n",
        "\n",
        "    # Realizar la actualización\n",
        "    os_client.update(index=index_name, id=doc_id, body=update_body)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recuperar todos los topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = 'topic'\n",
        "\n",
        "db_topics = []\n",
        "for i, doc in enumerate(Topic.search().query().scan()):\n",
        "    db_topics.append(doc.to_dict())\n",
        "    print(db_topics[i]['index'], db_topics[i]['name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recuperar documento mas cercano a un topico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = 'topic'\n",
        "search_query = {\n",
        "    'query': {\n",
        "        'match': {\n",
        "            'index': 6  # Sustituir 'campo' y 'valor' por campo y valor de búsqueda\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda\n",
        "response = os_client.search(\n",
        "                            body=search_query,\n",
        "                            index=index_name\n",
        ")\n",
        "\n",
        "texto = response['hits']['hits'][0]['_source']\n",
        "\n",
        "#Imprimir los resultados\n",
        "print(f\"Topico: {response['hits']['hits'][0]['_source']['name']}\")\n",
        "print(\"\\n\"+ texto['best_doc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nuevo documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_doc = \"Bitcoin esta en alza\"\n",
        "new_doc = response['hits']['hits'][0]['_source']['news']\n",
        "new_doc_embedding = topic_model.embedding_model.embed(new_doc)\n",
        "\n",
        "# Buscamos en la base a que topico pertenece el nuevo documento\n",
        "query = {\n",
        "    \"size\": 1,\n",
        "    \"query\": {\n",
        "        \"knn\": {\n",
        "            \"vector\": {\n",
        "                \"vector\": list(new_doc_embedding),\n",
        "                \"k\" : 3\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "response = os_client.search(index='topic', body=query)\n",
        "\n",
        "print(f\"Topico: {response['hits']['hits'][0]['_source']['name']}\")\n",
        "print(f\"Estimacion: {response['hits']['hits'][0]['_source']['similarity_threshold']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Busqueda de un documento por su indice, topico asociado, keywords, entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "index_name = 'news'\n",
        "search_query = {\n",
        "    'query': {\n",
        "        'match': {\n",
        "            '_id': '105640350'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda\n",
        "response = os_client.search(\n",
        "                            body=search_query,\n",
        "                            index=index_name\n",
        ")\n",
        "print(f\"Texto de Noticia: {response['hits']['hits'][0]['_source']['news'][:200]}...\\n\")\n",
        "\n",
        "new_doc_embedding = topic_model.embedding_model.embed(response['hits']['hits'][0]['_source']['news'])\n",
        "\n",
        "# Define el índice y el campo del vector\n",
        "index_name = 'topic'\n",
        "vector_field = 'vector'\n",
        "\n",
        "# Crear una consulta KNN para buscar el embedding más similar\n",
        "knn_query = {\n",
        "    \"size\": 1,  # Número de resultados que deseas obtener, en este caso 1\n",
        "    \"query\": {\n",
        "        \"knn\": {\n",
        "            vector_field: {\n",
        "                \"vector\": new_doc_embedding,\n",
        "                \"k\": 3  # Número de vecinos más cercanos\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda\n",
        "response_topic = os_client.search(index=index_name, body=knn_query)\n",
        "\n",
        "# Obtener el tópico más cercano\n",
        "if response_topic['hits']['total']['value'] > 0:\n",
        "    closest_topic = response_topic['hits']['hits'][0]['_source']\n",
        "    print(f\"El nuevo documento pertenece al tópico: {closest_topic['index']}\")\n",
        "    print(closest_topic['name'])\n",
        "    print(f\"Estimacion: {closest_topic['similarity_threshold']}\")\n",
        "    print(f\"Keywords del topico: {closest_topic['keywords']}\")\n",
        "    print(f\"Entidades del topico: {closest_topic['entities']}\")\n",
        "\n",
        "else:\n",
        "    print(\"No se encontró un tópico cercano.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agrupamiento de topicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = 'topic'\n",
        "\n",
        "db_topics = []\n",
        "for i, doc in enumerate(Topic.search().query().scan()):\n",
        "    db_topics.append(doc.to_dict())\n",
        "    print(db_topics[i]['index'], db_topics[i]['name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Agrupando por embeddings cercanos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_embeddings = topic_model.topic_embeddings_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reducir la dimensionalidad a 3D usando UMAP\n",
        "umap_model = UMAP(n_neighbors=5, n_components=3, metric='cosine')\n",
        "umap_embeddings = umap_model.fit_transform(topic_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame para los embeddings y los IDs de los tópicos\n",
        "df = pd.DataFrame(umap_embeddings, columns=['UMAP Dimension 1', 'UMAP Dimension 2', 'UMAP Dimension 3'])\n",
        "df['Topic'] = topic_model.get_topic_info()['Topic'].values\n",
        "\n",
        "# Crear la gráfica 3D interactiva usando Plotly\n",
        "fig = px.scatter_3d(df, x='UMAP Dimension 1', y='UMAP Dimension 2', z='UMAP Dimension 3',\n",
        "                    text='Topic', title='Embeddings de los Tópicos Reducidos a 3D con UMAP',\n",
        "                    width=1000, height=800)  # Ajustar el tamaño del gráfico\n",
        "\n",
        "# Mostrar la gráfica\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminamos el topico -1\n",
        "new_topic_embeddings = topic_embeddings[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular la similitud del coseno entre los embeddings de los tópicos\n",
        "similarities = cosine_similarity(new_topic_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear una matriz de similitud excluyendo la diagonal\n",
        "np.fill_diagonal(similarities, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encontrar los pares de tópicos más cercanos\n",
        "topic_pairs = np.dstack(np.unravel_index(np.argsort(similarities.ravel())[::-1], similarities.shape))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar los 5 pares de tópicos más cercanos\n",
        "for i in range(10):\n",
        "    topic_id_1, topic_id_2 = topic_pairs[i]\n",
        "    similarity_score = similarities[topic_id_1, topic_id_2]\n",
        "    print(f\"Topico {topic_id_1} y Topico {topic_id_2} tienen una similitud de: {similarity_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics_to_merge = [16, 17]\n",
        "\n",
        "id_docs_to_merge = []\n",
        "for topic in db_topics:\n",
        "    if topic['index'] in topics_to_merge:\n",
        "        id_docs_to_merge.append(topic['docs'].keys())\n",
        "\n",
        "list_id_docs_to_merge = [ item for sublist in id_docs_to_merge for item in sublist ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = 'news'\n",
        "\n",
        "# Construir el cuerpo de la solicitud para `mget`\n",
        "body = {\n",
        "    \"docs\": [{\"_index\": \"news\", \"_id\": int(doc_id)} for doc_id in list_id_docs_to_merge]\n",
        "}\n",
        "\n",
        "# Realizar la solicitud `mget`\n",
        "response = os_client.mget(body=body)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx_relativo = []\n",
        "docs_input = []\n",
        "for i, doc in enumerate(response['docs']):\n",
        "    idx_relativo.append(doc['_id'])\n",
        "    docs_input.append(doc['_source']['news'])\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(docs_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_model.merge_topics(docs_input, topics_to_merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar la busqueda de todas las noticias no procesadas ( False ) en la base (al menos 10.000)\n",
        "index_name = 'news'\n",
        "search_query = {\n",
        "    'query': {\n",
        "        'match': {\n",
        "            'process': True\n",
        "        }\n",
        "    },\n",
        "    'size': 10000\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda\n",
        "response = os_client.search( body=search_query, index=index_name )\n",
        "\n",
        "db_news = []\n",
        "for reg in response['hits']['hits']:\n",
        "    _id =  reg['_id']\n",
        "    title =  reg['_source']['title']\n",
        "    news =  reg['_source']['news']\n",
        "    try:\n",
        "        keywords =  reg['_source']['keywords'] \n",
        "    except:\n",
        "        keywords = ['']\n",
        "    try:\n",
        "        entities =  reg['_source']['entities'] \n",
        "    except:\n",
        "        entities = ['']\n",
        "    created_at =  reg['_source']['created_at'] \n",
        "    \n",
        "    db_news.append([_id, title, news, keywords, entities, created_at])\n",
        "\n",
        "df_news = pd.DataFrame(db_news , columns=[\"indice\", \"titulo\", \"noticia\", \"keywords\", \"entidades\", \"creado\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "T = topic_model.get_document_info(data)\n",
        "docs_per_topics = T.groupby([\"Topic\"]).apply(lambda x: x.index).to_dict()\n",
        "\n",
        "# Obtener los IDs de los documentos y sus probabilidades \n",
        "docs_IDs = {}\n",
        "doc_probs_x_topic = []\n",
        "for doc_idx in docs_per_topics[topic]:\n",
        "    \n",
        "    docs_IDs[df_news.indice[doc_idx]] = probs[doc_idx]\n",
        "    doc_probs_x_topic.append(probs[doc_idx])\n",
        "\n",
        "# Calcular la media, el desvío estándar\n",
        "mean = np.mean(doc_probs_x_topic)\n",
        "std_dev = np.std(doc_probs_x_topic)\n",
        "threshold = mean - std_dev\n",
        "\n",
        "# Filtra los docs que superan o igualan al valor del umbral calculado\n",
        "filter = {}\n",
        "for k,v in docs_IDs.items():\n",
        "    if v >= threshold:\n",
        "        filter[k] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ordeno de mayor a menor\n",
        "ids_filter_sort = dict(sorted(filter.items(), key=lambda item: item[1], reverse=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'105638222': 1.0,\n",
              " '105628246': 1.0,\n",
              " '105641111': 1.0,\n",
              " '105595584': 1.0,\n",
              " '105579195': 1.0,\n",
              " '105593527': 1.0,\n",
              " '105580036': 1.0,\n",
              " '105558763': 1.0,\n",
              " '105595323': 1.0,\n",
              " '105579437': 1.0,\n",
              " '105593407': 0.9591836188380196,\n",
              " '105594298': 0.9536858051294697,\n",
              " '105595318': 0.8797894030692698,\n",
              " '105579944': 0.8765740589839246,\n",
              " '105650270': 0.8544252505331561,\n",
              " '105595196': 0.6497119700491902}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids_filter_sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "title_filter_sort = [ df_news.loc[df_news['indice'] == idx].values[0][1] for idx in ids_filter_sort.keys() ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['El régimen de Nicolás Maduro excarceló al youtuber acusado de terrorismo en Venezuela',\n",
              " 'Autismo en adultos: la importancia de derribar los estigmas para mejorar su entendimiento',\n",
              " 'La lectura en voz alta: clave para el desarrollo infantil en el hogar y la escuela',\n",
              " 'Dieron de alta a Roxy Vázquez tras ser internada: \"Fue un cuadro viral severo\"',\n",
              " 'Internaron nuevamente a Jorge Lanata',\n",
              " 'Sube la nafta más del 4 por ciento: cuánto cuesta el combustible desde abril',\n",
              " 'Subte: reabrió la estación Facultad de Medicina de la Línea D',\n",
              " 'Atentado en Israel: un terrorista palestino acuchilló a un niño y fue abatido por la policía - MDZ Online',\n",
              " 'Bombardeo de Israel a la embajada de Irán en Siria mata a 8 personas',\n",
              " 'Israel bombardea la capital de Siria: hay seis muertos',\n",
              " 'Más aumentos: el Gobierno desreguló el precio del pan y la yerba',\n",
              " \"Podemos recurre al TC para que el Supremo investigue su querella contra el juez García Castellón por supuesto 'lawfare'\",\n",
              " 'Dos generales de la Guardia Revolucionaria y otras 6 personas murieron tras un ataque israelí contra el consulado de Irán en Damasco',\n",
              " 'ANSES confirmó cuánto cobran AUH y AUE en abril y las fechas de pago',\n",
              " '\"Villa Mitre será tan duro como lo fue River el viernes\", dijo el DT de Huracán',\n",
              " 'Un ataque aéreo israelí destruyó edificio del consulado de Irán en Damasco']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title_filter_sort "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'El régimen de Nicolás Maduro excarceló al youtuber acusado de terrorismo en Venezuela Autismo en adultos: la importancia de derribar los estigmas para mejorar su entendimiento La lectura en voz alta: clave para el desarrollo infantil en el hogar y la escuela Dieron de alta a Roxy Vázquez tras ser internada: \"Fue un cuadro viral severo\" Internaron nuevamente a Jorge Lanata Sube la nafta más del 4 por ciento: cuánto cuesta el combustible desde abril Subte: reabrió la estación Facultad de Medicina de la Línea D Atentado en Israel: un terrorista palestino acuchilló a un niño y fue abatido por la policía - MDZ Online Bombardeo de Israel a la embajada de Irán en Siria mata a 8 personas Israel bombardea la capital de Siria: hay seis muertos Más aumentos: el Gobierno desreguló el precio del pan y la yerba Podemos recurre al TC para que el Supremo investigue su querella contra el juez García Castellón por supuesto \\'lawfare\\' Dos generales de la Guardia Revolucionaria y otras 6 personas murieron tras un ataque israelí contra el consulado de Irán en Damasco ANSES confirmó cuánto cobran AUH y AUE en abril y las fechas de pago \"Villa Mitre será tan duro como lo fue River el viernes\", dijo el DT de Huracán Un ataque aéreo israelí destruyó edificio del consulado de Irán en Damasco'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join(title_filter_sort)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>indice</th>\n",
              "      <th>titulo</th>\n",
              "      <th>noticia</th>\n",
              "      <th>keywords</th>\n",
              "      <th>entidades</th>\n",
              "      <th>creado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>105638886</td>\n",
              "      <td>Paso a paso para invertir en criptomonedas y c...</td>\n",
              "      <td>Las criptomonedas se caracterizan por usar red...</td>\n",
              "      <td>[moneda, monedas virtuales, bitcoin, criptomon...</td>\n",
              "      <td>[Tether US, Elon Musk, Rodrigo Sura, Nayib Buk...</td>\n",
              "      <td>2024-07-02T20:22:51.549910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>105628162</td>\n",
              "      <td>Petro calificó de \"golpe antidemocrático\" la i...</td>\n",
              "      <td>Declaraciones de Gustavo Petro durante la inve...</td>\n",
              "      <td>[derecho, comunidad internacional, elecciones,...</td>\n",
              "      <td>[Gustavo Petro, Leopoldo López, Corina Yoris, ...</td>\n",
              "      <td>2024-07-02T20:22:51.552599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>105638375</td>\n",
              "      <td>Por primera vez, Nicole Neumann reveló los mot...</td>\n",
              "      <td>Años felices en familia: Nicole Neumann junto ...</td>\n",
              "      <td>[hijas, momento, vida, modelo, hija, días]</td>\n",
              "      <td>[Nicole Neumann, Fabián Cubero, Indiana Cubero...</td>\n",
              "      <td>2024-07-02T20:22:51.552599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105638272</td>\n",
              "      <td>Cómo es la fábrica de drones Shahed donde Ucra...</td>\n",
              "      <td>Un ataque ucraniano con drones en la región ce...</td>\n",
              "      <td>[producción, aviones, planta rusa, planta, alc...</td>\n",
              "      <td>[Washington Post, Roman Petushkov, John Hardie...</td>\n",
              "      <td>2024-07-02T20:22:51.553161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>105628203</td>\n",
              "      <td>Un proyecto de ley en Florida busca limitar la...</td>\n",
              "      <td>La iniciativa legislativa en Florida enfrenta ...</td>\n",
              "      <td>[orientación sexual, proyecto, banderas, espac...</td>\n",
              "      <td>[NBC Miami, CBS Miami, David Borrero, Randy Fi...</td>\n",
              "      <td>2024-07-02T20:22:51.553161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>105580240</td>\n",
              "      <td>Weretilneck no viaja a la vigilia de Malvinas ...</td>\n",
              "      <td>El gobernador de Río Negro, Alberto Weretilnec...</td>\n",
              "      <td>[coyuntura provincial, fecha, semana, gobernad...</td>\n",
              "      <td>[Río Negro, Alberto Weretilneck, Gustavo Melel...</td>\n",
              "      <td>2024-07-02T20:22:51.795240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>105558638</td>\n",
              "      <td>Conflicto con Colombia: El regreso del embajador</td>\n",
              "      <td>Con un comunicado conjunto entre las canciller...</td>\n",
              "      <td>[comunicado, relaciones, países, relaciones di...</td>\n",
              "      <td>[Javier Milei, Gustavo Petro, Gobierno colombi...</td>\n",
              "      <td>2024-07-02T20:22:51.795240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>105593542</td>\n",
              "      <td>Sorpresa en el INDEC: por qué ofertas de super...</td>\n",
              "      <td>Luis Caputo les pide a las grandes cadenas que...</td>\n",
              "      <td>[productos, grandes cadenas, cadenas, precios,...</td>\n",
              "      <td>[Luis Caputo]</td>\n",
              "      <td>2024-07-02T20:22:51.795240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>105592124</td>\n",
              "      <td>Tras la desregulación del precio de la yerba, ...</td>\n",
              "      <td>El Instituto Nacional de la Yerba Mate marcó q...</td>\n",
              "      <td>[valores, yerba, hoja verde, hoja, libre merca...</td>\n",
              "      <td>[Javier Milei, Marcelo Hacklander]</td>\n",
              "      <td>2024-07-02T20:22:51.795240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>105635355</td>\n",
              "      <td>Tiroteo en una escuela de Finlandia: un menor ...</td>\n",
              "      <td>Un alumno de 12 años falleció tras recibir est...</td>\n",
              "      <td>[tiroteo, agencia, forma pacífica, sospechoso,...</td>\n",
              "      <td>[Mari Rantanen]</td>\n",
              "      <td>2024-07-02T20:22:51.795240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        indice                                             titulo  \\\n",
              "0    105638886  Paso a paso para invertir en criptomonedas y c...   \n",
              "1    105628162  Petro calificó de \"golpe antidemocrático\" la i...   \n",
              "2    105638375  Por primera vez, Nicole Neumann reveló los mot...   \n",
              "3    105638272  Cómo es la fábrica de drones Shahed donde Ucra...   \n",
              "4    105628203  Un proyecto de ley en Florida busca limitar la...   \n",
              "..         ...                                                ...   \n",
              "995  105580240  Weretilneck no viaja a la vigilia de Malvinas ...   \n",
              "996  105558638   Conflicto con Colombia: El regreso del embajador   \n",
              "997  105593542  Sorpresa en el INDEC: por qué ofertas de super...   \n",
              "998  105592124  Tras la desregulación del precio de la yerba, ...   \n",
              "999  105635355  Tiroteo en una escuela de Finlandia: un menor ...   \n",
              "\n",
              "                                               noticia  \\\n",
              "0    Las criptomonedas se caracterizan por usar red...   \n",
              "1    Declaraciones de Gustavo Petro durante la inve...   \n",
              "2    Años felices en familia: Nicole Neumann junto ...   \n",
              "3    Un ataque ucraniano con drones en la región ce...   \n",
              "4    La iniciativa legislativa en Florida enfrenta ...   \n",
              "..                                                 ...   \n",
              "995  El gobernador de Río Negro, Alberto Weretilnec...   \n",
              "996  Con un comunicado conjunto entre las canciller...   \n",
              "997  Luis Caputo les pide a las grandes cadenas que...   \n",
              "998  El Instituto Nacional de la Yerba Mate marcó q...   \n",
              "999  Un alumno de 12 años falleció tras recibir est...   \n",
              "\n",
              "                                              keywords  \\\n",
              "0    [moneda, monedas virtuales, bitcoin, criptomon...   \n",
              "1    [derecho, comunidad internacional, elecciones,...   \n",
              "2           [hijas, momento, vida, modelo, hija, días]   \n",
              "3    [producción, aviones, planta rusa, planta, alc...   \n",
              "4    [orientación sexual, proyecto, banderas, espac...   \n",
              "..                                                 ...   \n",
              "995  [coyuntura provincial, fecha, semana, gobernad...   \n",
              "996  [comunicado, relaciones, países, relaciones di...   \n",
              "997  [productos, grandes cadenas, cadenas, precios,...   \n",
              "998  [valores, yerba, hoja verde, hoja, libre merca...   \n",
              "999  [tiroteo, agencia, forma pacífica, sospechoso,...   \n",
              "\n",
              "                                             entidades  \\\n",
              "0    [Tether US, Elon Musk, Rodrigo Sura, Nayib Buk...   \n",
              "1    [Gustavo Petro, Leopoldo López, Corina Yoris, ...   \n",
              "2    [Nicole Neumann, Fabián Cubero, Indiana Cubero...   \n",
              "3    [Washington Post, Roman Petushkov, John Hardie...   \n",
              "4    [NBC Miami, CBS Miami, David Borrero, Randy Fi...   \n",
              "..                                                 ...   \n",
              "995  [Río Negro, Alberto Weretilneck, Gustavo Melel...   \n",
              "996  [Javier Milei, Gustavo Petro, Gobierno colombi...   \n",
              "997                                      [Luis Caputo]   \n",
              "998                 [Javier Milei, Marcelo Hacklander]   \n",
              "999                                    [Mari Rantanen]   \n",
              "\n",
              "                         creado  \n",
              "0    2024-07-02T20:22:51.549910  \n",
              "1    2024-07-02T20:22:51.552599  \n",
              "2    2024-07-02T20:22:51.552599  \n",
              "3    2024-07-02T20:22:51.553161  \n",
              "4    2024-07-02T20:22:51.553161  \n",
              "..                          ...  \n",
              "995  2024-07-02T20:22:51.795240  \n",
              "996  2024-07-02T20:22:51.795240  \n",
              "997  2024-07-02T20:22:51.795240  \n",
              "998  2024-07-02T20:22:51.795240  \n",
              "999  2024-07-02T20:22:51.795240  \n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "x_ids, x_titles, umbral = topic_documents(topic, topic_model, probs, df_news, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNGxTNO4yTgb9k2r4ffbTN0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
